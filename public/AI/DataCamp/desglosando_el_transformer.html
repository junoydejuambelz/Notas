<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-09-21 Sun 07:54 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Desglosando el Transformer</title>
<meta name="generator" content="Org Mode" />
<link rel='stylesheet' href='/style.css' />
<script defer src='/navbar.js'></script>
<script>
  window.MathJax = {
  tex: {
  inlineMath: [['$', '$'], ['\\(', '\\)']],
  displayMath: [['$$', '$$'], ['\\[', '\\]']],
  processEscapes: true,
  processEnvironments: true,
  packages: {'[+]': ['ams', 'newcommand', 'configmacros', 'action', 'cancel', 'color', 'enclose', 'mhchem', 'unicode', 'verb']}
  },
  loader: {
  load: ['[tex]/newcommand', '[tex]/configmacros', '[tex]/action', '[tex]/cancel', '[tex]/color', '[tex]/enclose', '[tex]/mhchem', '[tex]/unicode', '[tex]/verb']
  },
  options: {
  skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
  };
  </script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
  <script>
  MathJax.startup.defaultReady();
  </script>
</head>
<body>
<div id="preamble" class="status">
<nav class="navbar">
        <div class="navbar-brand">
            <a href="/index.html">🏠 Home</a>
        </div>
        <div class="navbar-menu">
                <div class="navbar-item dropdown">
                        <a href="#" class="dropbtn">🖥️ Computación</a>
                        <div class="dropdown-content">
                                <a href="/Computacion/index.html">📋 Resumen</a>
                                <div class="dropdown-submenu">
                                        <a href="#" class="submenu-btn">⚙️ Algoritmos</a>
                                        <div class="submenu-content">
                                                <a href="/Computacion/Algoritmos/index.html">📋 Resumen</a>
                                                <a href="/Computacion/Algoritmos/pensamiento.html">🧠 Pensamiento algorítmico</a>
                                        </div>
                                </div>
                        </div>
                </div>
                <div class="navbar-item dropdown">
                        <a href="#" class="dropbtn">🤖 AI</a>
                        <div class="dropdown-content">
                                <a href="/AI/index.html">📋 Resumen</a>
                                <div class="dropdown-submenu">
                                        <a href="#" class="submenu-btn">📚 CS229</a>
                                        <div class="submenu-content">
                                                <a href="/AI/CS229/index.html">📋 Resumen</a>
                                                <a href="/AI/CS229/AprendizajeSupervisado/aprendizaje_supervisado.html">🎯 Aprendizaje Supervisado</a>
                                                <a href="/AI/CS229/AprendizajeSupervisado/regresion_lineal.html">📈 Regresión Lineal</a>
                                        </div>
                                </div>
                                <div class="dropdown-submenu">
                                        <a href="#" class="submenu-btn">🏗️ DataCamp</a>
                                        <div class="submenu-content">
                                                <a href="/AI/DataCamp/index.html">📋 Resumen</a>
                                                <a href="/AI/DataCamp/desglosando_el_transformer.html">🔍 Desglosando el Transformer</a>
                                                <a href="/AI/DataCamp/embedding_y_codificacion_posicional.html">🔗 Embedding y Codificación Posicional</a>
                                        </div>
                                </div>
                        </div>
                </div>
                <div class="navbar-item dropdown">
                        <a href="#" class="dropbtn">🔤 Tipos</a>
                        <div class="dropdown-content">

                                <div class="dropdown-submenu">
                                        <a href="#" class="submenu-btn">✍️ Pruebas y tipos</a>
                                        <div class="submenu-content">
                                                <a href="/Tipos/ProofsAndTypes/index.html">📋 Resumen </a>
                                                <a href="/Tipos/ProofsAndTypes/sentido.html">🧠 Sentido, denotación y semántica</a>
                                        </div>
                                </div>

                                <div class="dropdown-submenu">
                                        <a href="#" class="submenu-btn">🔬 HoTT</a>
                                        <div class="submenu-content">
                                                <div class="dropdown-submenu">
                                                        <a href="#" class="submenu-btn">🔬 HoTT (Carnegie Mellon)</a>
                                                        <div class="submenu-content">
                                                                <a href="/HoTT/index.html">📋 Resumen</a>
                                                                <a href="/HoTT/introduccion.html">🚀 Introducción</a>
                                                                <a href="/HoTT/juicios.html">⚖️ Juicios</a>
                                                                <a href="/HoTT/transitividad.html">🔛 Transitividad </a>
                                                                <a href="/HoTT/exponenciales.html">🗼 Exponenciales</a>
                                                                <a href="/HoTT/igualdad.html">🟰 Igualdad</a>
                                                        </div>
                                                </div>

                                                <div class="dropdown-submenu">
                                                        <a href="#" class="submenu-btn">🔬 Introducción a HoTT (Rijke)</a>
                                                        <div class="submenu-content">
                                                                <a href="/Tipos/Rijke/index.html">📋 Resumen </a>
                                                        </div>
                                                </div>
                                        </div>
                                </div>

                                <div class="dropdown-submenu">
                                        <a href="#" class="submenu-btn">🖥️ Lean</a>
                                        <div class="submenu-content">
                                                <a href="/Tipos/Lean/index.html">📋 Resumen </a>
                                        </div>
                                </div>
                        </div>
                </div>
        </div>
  </nav>
</div>
<div id="content" class="content">
<h1 class="title">Desglosando el Transformer</h1>
<div id="outline-container-org4d00b4f" class="outline-2">
<h2 id="org4d00b4f">El artículo que lo cambió todo</h2>
<div class="outline-text-2" id="text-org4d00b4f">
<ul class="org-ul">
<li>Attention is all you need (Ashish Vaswani)
<ul class="org-ul">
<li>Mecanismos de atención</li>
<li>Modelado de texto optimizado</li>
<li>Usado en los Large Language Models (LLMs)</li>
</ul></li>
</ul>
<p>
La arquitectura Transformer está formada por dos bloques, el bloque encoder y el bloque 
decoder
</p>
</div>
<div id="outline-container-org6950d5e" class="outline-3">
<h3 id="org6950d5e">Bloque encoder</h3>
<div class="outline-text-3" id="text-org6950d5e">
<ul class="org-ul">
<li>Multiples capas idénticas</li>
<li><b>Lee</b> y <b>procesa</b> el input</li>
<li>Genera representaciones numéricas ricas en contexto</li>
<li>Usa <b>self-attention</b> y <b>feed-forward networks</b></li>
</ul>
</div>
</div>
<div id="outline-container-org2d1269e" class="outline-3">
<h3 id="org2d1269e">Bloque decoder</h3>
<div class="outline-text-3" id="text-org2d1269e">
<ul class="org-ul">
<li>Secuencia input codificada \(\rightarrow\) secuencia output</li>
</ul>
</div>
</div>
<div id="outline-container-org47eb905" class="outline-3">
<h3 id="org47eb905">Positional encoding</h3>
<div class="outline-text-3" id="text-org47eb905">
<ul class="org-ul">
<li>Codifica la posición de cada token en la secuencia</li>
<li>El orden es crucial para modelar secuencias</li>
</ul>
</div>
</div>
<div id="outline-container-org65b23a1" class="outline-3">
<h3 id="org65b23a1">Mecanismos de atención</h3>
<div class="outline-text-3" id="text-org65b23a1">
<ul class="org-ul">
<li>Presta atención a los tokens importantes y sus relaciones</li>
<li>Mejora la generación de texto</li>
</ul>
</div>
<div id="outline-container-org2436699" class="outline-4">
<h4 id="org2436699">Self-attention</h4>
<div class="outline-text-4" id="text-org2436699">
<ul class="org-ul">
<li>Le asigna pesos a los tokens</li>
<li>Captura dependencias a largo rango</li>
</ul>
</div>
</div>
<div id="outline-container-org4f825af" class="outline-4">
<h4 id="org4f825af">Multi-head attention</h4>
<div class="outline-text-4" id="text-org4f825af">
<ul class="org-ul">
<li>Parte el input en múltiples <b>heads</b></li>
<li>Las heads capturas patrones distintos, creando representaciones más ricas</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org104a460" class="outline-3">
<h3 id="org104a460">Position-wide feed-forward networks</h3>
<div class="outline-text-3" id="text-org104a460">
<ul class="org-ul">
<li>Neural Networks (NNs) simples que aplican transformaciones</li>
<li>Cada token es transformado de manera independiente</li>
<li>Independiente de la posición</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orga70d791" class="outline-2">
<h2 id="orga70d791">Transformers en PyTorch</h2>
<div class="outline-text-2" id="text-orga70d791">
<p>
PyTorch nos provee de una clase de alto nivel en <code>torch.nn</code> para definir arquitecturas. 
Toma cuatro parámetros principales:
</p>

<ul class="org-ul">
<li><code>d_model</code>: Dimensión de los inputs del modelo</li>
<li><code>nheads</code>: Número de attention heads</li>
<li><code>num_encoder_layers</code>: Número de capas del encoder</li>
<li><code>num_decoder_layers</code>: Número de capas del decoder</li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">import</span> torch.nn <span style="font-weight: bold;">as</span> nn

<span style="font-weight: bold; font-style: italic;">model</span> = nn.Transformer(
  d_model=512,
  nhead=8,
  num_encoder_layers=6,
  num_decoder_layers=6
)

<span style="font-weight: bold;">print</span>(model)
</pre>
</div>
</div>
</div>
</div>
</body>
</html>
